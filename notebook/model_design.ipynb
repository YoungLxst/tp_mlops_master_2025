{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95593614",
   "metadata": {},
   "source": [
    "# MLOPS\n",
    "\n",
    "First project of the mlops cours. It needed to make a deep learning model that expres the feeling of text data and train it in a mlflow serve\n",
    "\n",
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c897d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c3fdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "1    10046\n",
       "0     9954\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/train.csv', index_col=0)\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True).iloc[:20000]\n",
    "df_test = pd.read_csv('../data/test.csv', index_col=0, nrows=5000)\n",
    "df_validation = pd.read_csv('../data/valid.csv', index_col=0,nrows=5000)\n",
    "\n",
    "df_train[\"polarity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04c9074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c302c",
   "metadata": {},
   "source": [
    "So the data is Film review with 2 colones usable. The review and the polarity(label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4973b423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "film-url    0\n",
       "review      0\n",
       "polarity    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf244f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review is between 1 and 373 words long\n",
      "and have an average of 91.80115 words\n"
     ]
    }
   ],
   "source": [
    "l = list(df_train[\"review\"])\n",
    "lenths = [len(i.split()) for i in l]\n",
    "print(\"review is between\", np.min(lenths), \"and\", np.max(lenths), \"words long\\nand have an average of\", np.mean(lenths), \"words\")\n",
    "del l, lenths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9ddc0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Nettoyage du texte - suppression des caractères spéciaudf_train[\"review\"] = df_train[\"review\"].apply(lambda x: re.sub(r'[^éèêa-zA-Z\\s]', '', x)dftrin[\"review\"] = dftrain[\"review\"].apply(lambda x: re.sub(r'[^éèêa-zA-Z\\s]', '', x))\n",
    "# df_train[\"review\"] = df_train[\"review\"].apply(lambda x: re.sub(r'[^éèêa-zA-Z\\s]', '', x))\n",
    "# df_test[\"review\"] = df_test[\"review\"].apply(lambda x: re.sub(r'[^éèêa-zA-Z\\s]', '', x))\n",
    "# df_validation[\"review\"] = df_validation[\"review\"].apply(lambda x: re.sub(r'[^éèêa-zA-Z\\s]', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b968acad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4/5 Un bon film qui en étonnera plus de 1 je p...\n",
       "1        Vu 2 fois en 3 jours : jeu époustouflant, mise...\n",
       "2        J'ai grandi avec ce film pour référence en ce ...\n",
       "3        Ce film est d'une telle beauté que maintenant,...\n",
       "4        ....Je viens de visionner et j'étais par momen...\n",
       "                               ...                        \n",
       "19995    excellent divertissement émouvant,dramatique e...\n",
       "19996    tres beau documentaire - un homme se fait taba...\n",
       "19997    Quand on n'a pas lu le bouquin, et qu'on voit ...\n",
       "19998    Une tache dans la carrière de Patrice Leconte,...\n",
       "19999    Une faute de gout, une comédie italienne resse...\n",
       "Name: review, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f3fa37",
   "metadata": {},
   "source": [
    "## vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f058b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ilian\\miniconda3\\envs\\mlops\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ca', 'cinquantieme', 'cinquieme', 'dela', 'deuxieme', 'deuxiemement', 'dixieme', 'douzieme', 'excepte', 'he', 'huitieme', 'neuf', 'neuvieme', 'notres', 'onzieme', 'premiere', 'premierement', 'qu', 'quatrieme', 'quatriemement', 'quelqu', 'septieme', 'sixieme', 'troisieme', 'troisiemement', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorize = TfidfVectorizer(max_features=5000, strip_accents='ascii', lowercase=True, stop_words=list(fr_stop)) \n",
    "vectorize.fit(df_train[\"review\"]) \n",
    "X_train = vectorize.transform(df_train[\"review\"]) \n",
    "X_test = vectorize.transform(df_test[\"review\"]) \n",
    "X_validation = vectorize.transform(df_validation[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4cd23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train = pd.DataFrame(X_train.toarray())\n",
    "df_X_test = pd.DataFrame(X_test.toarray())\n",
    "df_X_validation = pd.DataFrame(X_validation.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93cf9c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train[\"polarity\"]=df_train[\"polarity\"]\n",
    "df_X_test[\"polarity\"]=df_test[\"polarity\"]\n",
    "df_X_validation[\"polarity\"]=df_validation[\"polarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f940316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train.to_csv('../data/exp_train.csv',index=False)\n",
    "df_X_test.to_csv('../data/exp_test.csv',index=False)\n",
    "df_X_validation.to_csv('../data/exp_valid.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fff91215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First document TF-IDF features:\n",
      "(20000, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(\"First document TF-IDF features:\")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a1d2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_test, X_train, X_validation, df_X_test, df_X_train, df_X_validation, vectorize, df_validation, df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4717ad32",
   "metadata": {},
   "source": [
    "## modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76735402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from datetime import datetime\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "class PolarityNN(nn.Module):\n",
    "    \"\"\"\n",
    "        this model is for film review to predict if the review is good or bad\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=5000, hidden_size=128):\n",
    "        super(PolarityNN, self).__init__()\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        rand_suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=4))\n",
    "        self.model_name = f\"PolarityNN_{timestamp}_{rand_suffix}\" \n",
    "        \n",
    "        # neural layer\n",
    "        self.model = nn.Sequential(\n",
    "            # layer: 5000 -> 128\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # layer: 128 -> 64\n",
    "            nn.Linear(hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # output layer: 64 -> 1 (classification binaire)\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x => (batch_size, 5000)\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            probs = self.forward(x)\n",
    "            return (probs > 0.5).float()\n",
    "            \n",
    "    def train_polarityNN(self, train_loader, val_loader, num_epochs=10, learning_rate=0.001):\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        \n",
    "        progress =tqdm(range(num_epochs*len(train_loader)))\n",
    "        for epoch in range(num_epochs):\n",
    "            # torch training mode\n",
    "            self.train()\n",
    "            total_train_loss = 0\n",
    "            \n",
    "            for batch_x, batch_y in train_loader:\n",
    "                # Forward pass\n",
    "                outputs = self(batch_x)\n",
    "                loss = criterion(outputs, batch_y.float().view(-1, 1))\n",
    "                \n",
    "                # Backward pass and optim\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_train_loss += loss.item()\n",
    "                progress.update(1)\n",
    "                progress.refresh()\n",
    "            avg_train_loss = total_train_loss / len(train_loader)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            \n",
    "            # torch eval\n",
    "            self.eval()\n",
    "            total_val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_x, batch_y in val_loader:\n",
    "                    outputs = self(batch_x)\n",
    "                    loss = criterion(outputs, batch_y.float().view(-1, 1))\n",
    "                    total_val_loss += loss.item()\n",
    "\n",
    "                    predicted = (outputs > 0.5).float()\n",
    "                    total += batch_y.size(0)\n",
    "                    correct += (predicted.view(-1) == batch_y).sum().item()\n",
    "            \n",
    "            avg_val_loss = total_val_loss / len(val_loader)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            tqdm.write(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "            tqdm.write(f'Train Loss: {avg_train_loss:.4f}')\n",
    "            tqdm.write(f'Val Loss: {avg_val_loss:.4f}')\n",
    "            tqdm.write(f'Val Accuracy: {accuracy:.2f}%\\n')\n",
    "        \n",
    "        return train_losses, val_losses\n",
    "    \n",
    "    def save(self, folder_name=\"trained\"):\n",
    "        base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        save_dir = os.path.join(base_dir, folder_name)\n",
    "        \n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        path = os.path.join(save_dir, f\"{self.model_name}.pt\")\n",
    "        \n",
    "        torch.save(self.state_dict(), path)\n",
    "        print(f\"Model saved at: {path}\")\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cb0f97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  4991  4992  4993  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "   4994  4995  4996  4997  4998  4999  polarity  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0         1  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0         1  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0         1  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0         1  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0         0  \n",
       "\n",
       "[5 rows x 5001 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/exp_train.csv')\n",
    "df_test = pd.read_csv('../data/exp_test.csv', nrows=2000)\n",
    "df_val = pd.read_csv('../data/exp_valid.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a035e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = TensorDataset(torch.tensor(df_train.drop(columns=\"polarity\").to_numpy(),dtype=torch.float),torch.tensor(df_train[\"polarity\"].to_numpy(), dtype=torch.float))\n",
    "test_tensor = TensorDataset(torch.tensor(df_test.drop(columns=\"polarity\").to_numpy(),dtype=torch.float),torch.tensor(df_test[\"polarity\"].to_numpy(), dtype=torch.float))\n",
    "val_tensor = TensorDataset(torch.tensor(df_val.drop(columns=\"polarity\").to_numpy(),dtype=torch.float),torch.tensor(df_val[\"polarity\"].to_numpy(), dtype=torch.float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30422ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = TensorDataset(torch.tensor(df_train.drop(columns=\"polarity\").to_numpy(),dtype=torch.float),torch.tensor(df_train[\"polarity\"].to_numpy(), dtype=torch.float))\n",
    "test_tensor = TensorDataset(torch.tensor(df_test.drop(columns=\"polarity\").to_numpy(),dtype=torch.float),torch.tensor(df_test[\"polarity\"].to_numpy(), dtype=torch.float))\n",
    "val_tensor = TensorDataset(torch.tensor(df_val.drop(columns=\"polarity\").to_numpy(),dtype=torch.float),torch.tensor(df_val[\"polarity\"].to_numpy(), dtype=torch.float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be654556",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_tensor, batch_size=30)\n",
    "test_loader = DataLoader(test_tensor, batch_size=30)\n",
    "val_loader = DataLoader(val_tensor, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80723f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16675 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 688/16675 [00:07<06:48, 39.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25]\n",
      "Train Loss: 0.3260\n",
      "Val Loss: 0.2394\n",
      "Val Accuracy: 89.95%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1357/16675 [00:13<03:17, 77.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25]\n",
      "Train Loss: 0.1834\n",
      "Val Loss: 0.2508\n",
      "Val Accuracy: 89.85%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2024/16675 [00:18<02:55, 83.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25]\n",
      "Train Loss: 0.1274\n",
      "Val Loss: 0.3026\n",
      "Val Accuracy: 89.70%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 2690/16675 [00:25<05:19, 43.82it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25]\n",
      "Train Loss: 0.0788\n",
      "Val Loss: 0.2710\n",
      "Val Accuracy: 89.20%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3357/16675 [00:31<02:49, 78.69it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25]\n",
      "Train Loss: 0.0606\n",
      "Val Loss: 0.4323\n",
      "Val Accuracy: 89.05%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4022/16675 [00:37<02:44, 76.76it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25]\n",
      "Train Loss: 0.0360\n",
      "Val Loss: 0.6649\n",
      "Val Accuracy: 88.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 4692/16675 [00:43<02:28, 80.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25]\n",
      "Train Loss: 0.0251\n",
      "Val Loss: 0.7987\n",
      "Val Accuracy: 88.60%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 5359/16675 [00:48<02:20, 80.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25]\n",
      "Train Loss: 0.0169\n",
      "Val Loss: 1.0829\n",
      "Val Accuracy: 88.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 6026/16675 [00:54<02:31, 70.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25]\n",
      "Train Loss: 0.0131\n",
      "Val Loss: 1.4712\n",
      "Val Accuracy: 88.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6688/16675 [01:00<02:01, 82.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25]\n",
      "Train Loss: 0.0116\n",
      "Val Loss: 1.2878\n",
      "Val Accuracy: 88.60%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 7359/16675 [01:05<01:56, 80.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25]\n",
      "Train Loss: 0.0122\n",
      "Val Loss: 1.4869\n",
      "Val Accuracy: 88.65%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 8023/16675 [01:11<01:51, 77.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25]\n",
      "Train Loss: 0.0108\n",
      "Val Loss: 1.4403\n",
      "Val Accuracy: 88.55%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 8692/16675 [01:19<02:09, 61.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25]\n",
      "Train Loss: 0.0108\n",
      "Val Loss: 1.6960\n",
      "Val Accuracy: 88.60%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 9357/16675 [01:26<02:10, 56.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25]\n",
      "Train Loss: 0.0083\n",
      "Val Loss: 1.8904\n",
      "Val Accuracy: 88.50%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 10025/16675 [01:33<01:43, 64.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25]\n",
      "Train Loss: 0.0080\n",
      "Val Loss: 1.9906\n",
      "Val Accuracy: 88.60%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 10690/16675 [01:39<01:38, 60.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25]\n",
      "Train Loss: 0.0080\n",
      "Val Loss: 1.9933\n",
      "Val Accuracy: 89.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 11359/16675 [01:46<01:19, 66.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25]\n",
      "Train Loss: 0.0075\n",
      "Val Loss: 2.0418\n",
      "Val Accuracy: 88.60%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 12024/16675 [01:53<01:33, 49.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25]\n",
      "Train Loss: 0.0075\n",
      "Val Loss: 2.2308\n",
      "Val Accuracy: 88.90%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 12691/16675 [02:00<01:14, 53.30it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25]\n",
      "Train Loss: 0.0064\n",
      "Val Loss: 2.2635\n",
      "Val Accuracy: 88.60%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 13358/16675 [02:07<01:00, 54.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25]\n",
      "Train Loss: 0.0075\n",
      "Val Loss: 2.5595\n",
      "Val Accuracy: 88.60%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 14026/16675 [02:14<00:39, 67.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25]\n",
      "Train Loss: 0.0084\n",
      "Val Loss: 2.1494\n",
      "Val Accuracy: 88.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 14692/16675 [02:23<00:33, 59.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25]\n",
      "Train Loss: 0.0073\n",
      "Val Loss: 2.2052\n",
      "Val Accuracy: 88.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 15360/16675 [02:30<00:21, 61.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25]\n",
      "Train Loss: 0.0066\n",
      "Val Loss: 2.5103\n",
      "Val Accuracy: 88.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 16027/16675 [02:38<00:10, 61.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25]\n",
      "Train Loss: 0.0072\n",
      "Val Loss: 2.3007\n",
      "Val Accuracy: 88.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16675/16675 [02:45<00:00, 100.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25]\n",
      "Train Loss: 0.0067\n",
      "Val Loss: 2.2797\n",
      "Val Accuracy: 88.85%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.32595861615470684,\n",
       "  0.18344305086506718,\n",
       "  0.12744797857386106,\n",
       "  0.07875471576703419,\n",
       "  0.06058747746030112,\n",
       "  0.03599515944682051,\n",
       "  0.025129523374388278,\n",
       "  0.01694756668839709,\n",
       "  0.013070438302824148,\n",
       "  0.011556760380098768,\n",
       "  0.01219957363811215,\n",
       "  0.010804984652338718,\n",
       "  0.010814896335359984,\n",
       "  0.008265953300408725,\n",
       "  0.0080289415914923,\n",
       "  0.008030035133953077,\n",
       "  0.007479197127874644,\n",
       "  0.007480609319812733,\n",
       "  0.006400956667810289,\n",
       "  0.0074880968213448884,\n",
       "  0.00841179771974228,\n",
       "  0.007303248721319285,\n",
       "  0.006554405912623364,\n",
       "  0.0072043465310689695,\n",
       "  0.006709857508571664],\n",
       " [0.23936297010574767,\n",
       "  0.2508171899105186,\n",
       "  0.30263835444712817,\n",
       "  0.2710432862835144,\n",
       "  0.4323046344763307,\n",
       "  0.6648916329966107,\n",
       "  0.7987228052537722,\n",
       "  1.0828683291207444,\n",
       "  1.4711851890801813,\n",
       "  1.287840352073979,\n",
       "  1.4869231340881965,\n",
       "  1.4402871107110935,\n",
       "  1.6959943778103967,\n",
       "  1.8903514984882186,\n",
       "  1.9906377260453318,\n",
       "  1.99333435788563,\n",
       "  2.0417609663042517,\n",
       "  2.230826181762699,\n",
       "  2.2635283768958927,\n",
       "  2.559456557570609,\n",
       "  2.149385299387435,\n",
       "  2.2051598034080624,\n",
       "  2.5102524927434158,\n",
       "  2.3006942835593,\n",
       "  2.2797190491236057])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PolarityNN()\n",
    "model.train_polarityNN(train_loader,val_loader, num_epochs=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
